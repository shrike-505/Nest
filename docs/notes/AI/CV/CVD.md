---
    comments: true
    tags: 
        - å¤§ä¸‰ä¸Šç¬”è®°
---

# è®¡ç®—æœºè§†è§‰å¯¼è®º

> ä»»è¯¾æ•™å¸ˆï¼šå‘¨æ™“å·  
> Reference: Umich EECS 498/598 Deep Learning for Computer Vision

## 01. intro

- CV Tasks
    - 3D é‡å»ºï¼ˆå…ƒç´ å®šä½ã€SLAMï¼‰
    - å›¾åƒç†è§£
    - å›¾åƒåˆæˆ

## 02. Review of Linear Algebra & Image Formation

å‘é‡&çŸ©é˜µå¤ä¹ ï¼šæˆ‘å»ï¼Œè¿™ä¸æ˜¯æˆ‘ä»¬æœ€å–œæ¬¢çš„çº¿æ€§ä»£æ•°å—

Each Matrix can be regarded as a geometric transformation

ä»¿å°„å˜æ¢ = çº¿æ€§å˜æ¢ + å¹³ç§»ï¼ŒUsing homogeneous coordinatesï¼š$(x', y', 1)^T = \begin{bmatrix} a & b & tx \\ c & d & ty \\ 0 & 0 & 1 \end{bmatrix} (x, y, 1)^T$

ç‰¹å¾å€¼çš„å‡ ä½•å«ä¹‰ï¼šå¯¹ç‰¹å¾å‘é‡è¿›è¡ŒçŸ©é˜µå½¢å¼çš„çº¿æ€§å˜æ¢åï¼Œæ–¹å‘ä¸å˜ï¼Œé•¿åº¦å˜ä¸ºåŸæ¥çš„ $\lambda$ å€

### Camera & Lens

è¯•ç€è®¾è®¡ä¸€ä¸ªç›¸æœº

idea1ï¼šç›´æ¥å°†ä¸€ç‰‡å¯ä»¥æ¥æ”¶ç‰©ä½“åå°„å…‰çš„è–„è†œæ”¾åœ¨ç‰©ä½“å‰é¢ï¼šç‰©ä½“ä¸Šä»»æ„ä¸€ç‚¹çš„å…‰éƒ½ä¼šç…§åˆ°è–„è†œçš„æ¯ä¸€å¤„ï¼Œå¯¼è‡´å¹¶ä¸æ˜¯ one-to-one æ¥å—å…‰çº¿

äºæ˜¯ idea2ï¼šåœ¨è–„è†œå‰é¢åŠ ä¸€ä¸ªå°å­”ï¼ˆapertureï¼‰ï¼Œåªå…è®¸é€šè¿‡å°å­”çš„å…‰çº¿ç…§åˆ°è–„è†œä¸Š

ä½†æ˜¯å°å­”å¹¶ä¸æ˜¯è¶Šå°è¶Šå¥½ï¼šä¼šå¯¼è‡´é€šè¿‡çš„å…‰çº¿å¤ªå°‘äº†ï¼Œä¸”è¿˜æœ‰è¡å°„ç°è±¡

!!! note "FOV"
    ![FOV](../assets/CVD1.png)

Aperture çš„å°ºå¯¸ç”±é•œç‰‡çš„ç›´å¾„åˆ»ç”»ï¼Œè®°ä¸º $D$

ä¸€ç§æ›´å¥½çš„æè¿°æ–¹å¼æ˜¯ f-numberï¼š$N = f/D$ï¼Œå…¶ä¸­ $f$ æ˜¯ç„¦è·ï¼Œå³é•œç‰‡ç„¦è·ä¸ç›´å¾„çš„æ¯”å€¼

### Geometric image formation

![pinhole](../assets/CVD2.png)

## 03. Image Processing

Convolution: $(f * g)(x) = \int_{-\infty}^{\infty} f(t) g(x - t) dt$

- f(t): conv kernel
- g(x - t): signal
- (f * g)(x): output signal

### Blurring

- é€šè¿‡å·ç§¯å®ç°å›¾åƒæ¨¡ç³Š
    - Box filter: å·ç§¯æ ¸å…¨ä¸º1
    - Gaussian filter: å·ç§¯æ ¸ä¸ºé«˜æ–¯åˆ†å¸ƒ

### Sharpening

å®è´¨æ˜¯ adding high frequencies

- Low Frequencyï¼šBlur(I)
- High Frequencyï¼šI - Blur(I)
- Sharpened Imageï¼šI + Î±(I - Blur(I))ï¼ŒÎ± æ§åˆ¶é”åŒ–ç¨‹åº¦

### Gradient detection filter

$\begin{bmatrix} -1 & 0 & 1 \\ -2 & 0 & 2 \\ -1 & 0 & 1 \end{bmatrix}$ï¼šæå–æ°´å¹³æ–¹å‘çš„ Gradient

$\begin{bmatrix} -1 & -2 & -1 \\ 0 & 0 & 0 \\ 1 & 2 & 1 \end{bmatrix}$ï¼šæå–å‚ç›´æ–¹å‘çš„ Gradient

Bilateral filterï¼šåœ¨ä¿æŒè¾¹ç¼˜çš„åŒæ—¶è¿›è¡Œæ¨¡ç³Š

### Image Sampling

TBD

## 04. Model fitting & Optimization


### Optimization

$\textbf{minimize} \quad f_0(x)$ï¼ˆobjective functionï¼‰

$\textbf{subject to} \quad f_i(x) \leq 0, i = 1, ..., m; \quad g_i(x) = 0, i = 1, ..., p$ï¼ˆå‰è€…ç§°ä¸ºä¸ç­‰å¼çº¦æŸï¼Œåè€…ç§°ä¸ºç­‰å¼çº¦æŸï¼‰

!!! example "Image Deblurring"
    æ¨¡ç³Šå›¾åƒçš„è¿˜åŸå¯çœ‹ä½œè¿½æ±‚ $\min_X \|Y - FX\|^2$ï¼Œå…¶ä¸­ $Y$ æ˜¯æ¨¡ç³Šå›¾åƒï¼Œ$X$ æ˜¯æ¸…æ™°å›¾åƒï¼Œ$F$ æ˜¯æ¨¡ç³Š kernel


### Model Fitting

A mathematical model $ğ‘ = ğ‘“_ğ‘¥(ğ‘)$ describes the relationship between input ğ‘ and output ğ‘, where x is model parameterã€‚å¦‚çº¿æ€§æ¨¡å‹ $b = a^T x$ã€‚

éœ€è¦æ‰¾åˆ°æœ€ä¼˜å‚æ•° $x^*$ï¼ˆå³ä» data ä¸­å­¦ä¹ å‚æ•°ï¼‰ï¼Œç»å…¸çš„æ–¹æ³•æ˜¯ä½¿ **å‡æ–¹è¯¯å·®ï¼ˆMSE, Mean Squared Errorï¼‰** æœ€å°åŒ–ï¼š$\hat{x} = \arg\min_x \sum_{i=1}^n (b_i - f_x(a_i))^2$

## 0?. Structure from Motion (SfM)

sfm æ˜¯é€šè¿‡ä¸€ç³»åˆ—ä¸åŒè§’åº¦æ‹æ‘„çš„ç…§ç‰‡ï¼Œè®¡ç®—3dæ¨¡å‹ä¸Šæ¯ä¸ªç‚¹çš„åæ ‡ï¼ˆæ„æˆç‚¹äº‘ï¼‰ï¼Œä»è€Œé‡å»ºå…¶3då»ºæ¨¡å’Œç›¸æœºçš„å‚æ•°

éœ€è¦å¤„ç†ä¸‰ä¸ªé—®é¢˜ï¼š

- ä¸‰ç»´åæ ‡æ€ä¹ˆæ˜ å°„åˆ°ç…§ç‰‡çš„äºŒç»´åæ ‡ï¼ˆcamera modelï¼‰

- æ€ä¹ˆåœ¨ä¸–ç•Œåæ ‡ç³»ä¸­è®¡ç®—ç›¸æœºçš„ä½ç½®ä¸æœå‘ï¼ˆcamera calibration & pose estimationï¼‰

- æ€ä¹ˆé‡å»º3dç‚¹äº‘ï¼ˆsfmï¼‰

ç›¸æœºæœ¬èº«çš„åæ ‡ç³»ï¼ˆç›¸æœºåæ ‡ç³»ï¼‰ï¼Œxyè½´ä½äºç›¸æœºå±å¹•å¹³é¢ï¼Œzè½´æ­£æ–¹å‘ä¸ºç›¸æœºçš„orientation

ç…§ç‰‡çš„ç”Ÿæˆï¼šä¸–ç•Œåæ ‡ç³»ä¸­çš„åæ ‡è½¬æ¢åˆ°ç›¸æœºåæ ‡ç³»ä¸‹ï¼ˆcoordinate transformationï¼‰ï¼Œå†æŠ•å½±åˆ°äºŒç»´å¹³é¢ä¸‹ï¼ˆperspective projectionï¼‰ï¼ŒäºŒç»´å¹³é¢çš„åæ ‡è½¬åŒ–ä¸ºåƒç´ ï¼ˆimage plane to image sensorï¼‰

å¤–å‚ï¼ˆä½ç½®å’Œæœå‘ï¼‰çŸ©é˜µå¤„ç†coordinate transï¼Œå†…å‚ï¼ˆåˆ†è¾¨ç‡ï¼Œç„¦è·ç­‰ï¼‰çŸ©é˜µå¤„ç†åé¢ä¸¤ä¸ªè¿‡ç¨‹

å¤–å‚ï¼šplacementï¼Œorientation

coor transï¼šxc=Rxw+t use homogeneous coordinates

å¤–å‚çŸ©é˜µ

perspective projectionï¼šxc-ï¼xi

im2imï¼šå†…å‚çŸ©é˜µ

decompose projection matrix

è§†è§‰æ ‡å®šé—®é¢˜

å‡å®šå†…å‚ä¸€ç›´æ±‚ç›¸æœºå¤–å‚ï¼ŒperspectiveNpoint

minimize reprojection error

epipolar geometry

## 08. Depth Estimation & 3D Reconstruction

ç¨ å¯†çš„ä¸‰ç»´é‡å»º

Depthï¼šç›®æ ‡ç‚¹åˆ°ç›¸æœºå¹³é¢çš„è·ç¦»ï¼›æœ‰å¾ˆå¤šåº”ç”¨ï¼šé¿éšœã€äººè„¸è¯†åˆ«

- Aä¸»åŠ¨å‘å°„ä¿¡å·åˆ°ç¯å¢ƒä¸­ï¼Œé€šè¿‡æ¥æ”¶åå°„ä¿¡å·è®¡ç®—è·ç¦»ï¼Œå¦‚é›·è¾¾


## 09. Deep Learning

### Linear Classifier

$x$ å’Œæƒé‡ $w$ ç›¸ä¼¼æ—¶ï¼Œå¾—åˆ°çš„ score $w^T x$ è¶Šå¤§

loss function for regression: MSE: $\Sum_i (f(x_i) - y_i)^2$

ä¸èƒ½ç”¨äº score based åˆ†ç±»é—®é¢˜ï¼Œå› ä¸º score æ˜¯è¿ç»­å€¼(-inf, +inf)ï¼Œéœ€è¦æŠŠ score è½¬åŒ–ä¸ºæ¦‚ç‡åˆ†å¸ƒ(0-1)

softmax function: $S_j = \frac{e^{f_j}}{\Sum_k e^{f_k}}$

cross-entropy loss: $D(groundtruth, prediction) = -\Sum_i y_i \log S_i$

### Neural Networks

çº¿æ€§ -> éçº¿æ€§ï¼ˆæ¿€æ´»å‡½æ•°ï¼‰ï¼šSigmoidï¼ŒRelu... å³æ¯ä¸ª perceptronï¼š$f(x) = \sigma(w^T x + b)$

multi-layer NN: $f(x) = \sigma(W_n \sigma(W_{n-1} ... \sigma(W_1 x + b_1) ... + b_{n-1}) + b_n)$

- Fully connected layers

### Convolutional Neural Networks

## 10. Recognition

### è¯­ä¹‰åˆ†å‰²ï¼ˆSemantic Segmentationï¼‰

![semantic segmentation](../assets/CVD3.png)

ä»…åŒºåˆ†**ä¸åŒç±»åˆ«**çš„åƒç´ å¹¶æ ‡æ³¨ï¼Œä¾‹å¦‚è¯´å›¾ç‰‡ä¸­æœ‰è®¸å¤šä¸ªåŒç§ç‰©ä½“ï¼ˆè®¸å¤šåªçŒ«ï¼‰ï¼Œè¿™æ—¶è¯­ä¹‰åˆ†å‰²åªæ ‡æ³¨å“ªäº›åƒç´ æ˜¯çŒ«ï¼Œè€Œä¸åŒºåˆ†è¯¥åƒç´ å±äºå“ªåªçŒ«ï¼ˆDo not differentiate instancesï¼‰

å¦‚ä½•å®ç°è¯­ä¹‰åˆ†å‰²ï¼Ÿ

- æ—©æœŸçš„æ–¹æ³•æ˜¯åˆ©ç”¨ sliding windowï¼Œåœ¨å›¾åƒä¸Šæ»‘åŠ¨ä¸€ä¸ªçª—å£ï¼Œå¯¹çª—å£å†…çš„åƒç´ åˆ©ç”¨ CNN è¿›è¡Œåˆ†ç±»ï¼Œå¾—åˆ°è¯¥çª—å£å†…åƒç´ çš„ç±»åˆ«æ ‡ç­¾ï¼Œè¿™æ ·å¤ªæ…¢äº†ï¼Œå¹¶ä¸” receptive field å¤ªå°
- Fully Convolutional Network (FCN)ï¼šmake all predictions at onceï¼Œè¾“å‡ºä¸€å¼ é¢„æµ‹å›¾ï¼ˆè¯­ä¹‰å›¾ï¼‰ï¼ŒæŸå¤±å‡½æ•°æ˜¯æ¯ä¸ªåƒç´ çš„äº¤å‰ç†µã€‚
    - High-resolution ->(via down-sampling) Low-resolution ->(via up-sampling) High-resolution
    - Upsampling(Unpooling)
        - ![upsampling](../assets/CVD4.png)
        - ![upsampling2](../assets/CVD5.png)
        - ç§°ä¸º Transposed Convolution
    - U-Net
        - skip connection: combine low-level features with high-level features to get better predictionï¼ˆä»ä¸‹é‡‡æ ·é˜¶æ®µä¸­çš„æŸä¸€å±‚ç›´æ¥skipåˆ°ä¸Šé‡‡æ ·é˜¶æ®µçš„æŸä¸ªå±‚ï¼Œä½¿å¾—æŸäº›å¯èƒ½åœ¨ä¸‹é‡‡æ ·è¿‡ç¨‹ä¸­ä¸¢å¤±çš„ç»†èŠ‚ä¿¡æ¯å¾—ä»¥ä¿ç•™ï¼‰
    - DeepLab
        - FCN + Atrous Convolution + CRF(Conditional Random Field)

Evaluation Metrics: IOU(Intersection over Union) = area(é¢„æµ‹é¢ç§¯ $\cap$ çœŸå®é¢ç§¯)/area(é¢„æµ‹é¢ç§¯ $\cup$ çœŸå®é¢ç§¯)

### Object Detection

Input: single RGB image

Output: A set of bounding boxes that denote objects

- Region Proposal: generate a set of candidate object bounding boxes - R-CNN
    - Bounding box çš„è´¨é‡ä¹Ÿé€šè¿‡ IOU æ¥è¡¡é‡

TBD

### Instance Segmentation

### Human Pose Estimation

åœ¨äººä½“ä¸Šå®šä¹‰ä¸€ç³»åˆ—å…³é”®ç‚¹ï¼ˆkeypointsï¼‰ï¼Œå¦‚å¤´é¡¶ã€è‚©è†€ã€è‚˜éƒ¨ã€æ‰‹è…•ã€è‡€éƒ¨ã€è†ç›–ã€è„šè¸ç­‰

- å•äºº
- å¤šäºº
    - Top-downï¼šåœ¨æ¯ä¸ª bounding box å†…è¿›è¡Œå•äºº pose estimationï¼ˆMask R-CNNï¼‰
    - Bottom-upï¼šå…ˆæ£€æµ‹æ‰€æœ‰å…³é”®ç‚¹ï¼Œå†å°†å…³é”®ç‚¹ç»„è£…æˆä¸åŒçš„äººï¼ˆOpenPoseï¼‰

### Others

å…‰æµï¼ˆOptical Flowï¼‰ï¼šæè¿°å›¾åƒä¸­åƒç´ ç‚¹çš„è¿åŠ¨

- FlowNet
- Raft

Video Classificationï¼šè¯†åˆ« actions

## Deep Learning for 3D Vision

### DL4 Feature Mapping

### DL4 Object Pose Estimation
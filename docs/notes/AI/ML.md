---
    comments: true
    tags: 
        - 大三上笔记
---

# 机器学习

> 任课教师：赵洲
> 参考教材：《机器学习》（周志华）

## Terminology

- 特征（Feature）：又称属性（Attribute）
- 属性值：属性的取值
- 样本（Sample）/示例（Instance）：数据集中的每一行记录（一个对象的输入）**不含标记**
- 样本维度：样本的属性个数
- 特征张成的空间：属性空间/输入空间
- 标记张成的空间：输出空间
- 样例（Example）：示例+标记
- 任务：
    - 预测任务：根据标记的取值情况
        - 分类任务：标记是离散值（二分类、多分类）
        - 回归任务：标记是连续值
        - 聚类任务：标记为空值，对示例进行分组
    - 监督学习：所有 Instance 都有标记（分类、回归）
    - 无监督学习：所有 Instance 都没有标记（聚类）
    - 半监督学习：少量 Instance 有标记，大量没有标记

机器学习的根本目标是提高模型的**泛化能力**（Generalization），即在未见过的数据上也能有良好的表现——依靠历史数据来逼近泛化能力（假设历史和未来**独立同分布**）。

归纳偏好：学习过程中对某种类型假设的偏好

No free lunch theorem：如果算法 A 在某些问题上表现优于算法 B，那么必然存在另一些问题，算法 B 优于算法 A。

## 模型评估与选择

![模型评估与选择](./assets/ML1.png)

!!! note "错误率与误差"
    - 错误率（Error Rate）：分类错误的样本数占总样本数的比例
    - 误差（Error）：样本真实输出与预测输出之间的差距

- 过拟合：模型学习能力过强，将训练样本本身的某些特质都当作所有样本的一般性质，导致泛化能力下降
    - Sol：优化目标加正则项，early stopping
- 欠拟合：对训练样本的一般性质都没有学到
    - Sol：增加模型复杂度，决策树（拓展分支），神经网络（增加训练轮数）

??? note "将数据集分成训练集和测试集（评估方法）"
    - 留出法（Hold-out）：将数据集随机分成训练集和测试集
        - 划分尽可能保持数据分布的一致性
        - 分层采样（Stratified Sampling）：保持类别比例一致
    - 交叉验证（Cross Validation）：将数据集分成 k 份，轮流用 k-1 份做训练集，1 份做测试集，最终得到 k 个测试结果，取平均值作为返回结果
    - 自助法
        - ![自助法](./assets/ML2.png)

在进行模型评估与选择时，除了对适用学习算法进行选择，还需对算法参数进行设定（调参）。

### 经验性能的指标多样：性能度量

对模型泛化能力的评价标准

- 回归任务常用**均方误差**
    - $E(f;D) = \frac{1}{m} \sum_{i=1}^{m} (f(x_i)-y_i)^2$
- 对分类任务，错误率和精度最常用（即分对/错样本占样本总数的比例）
    - 错误率：$E(f;D) = \frac{1}{m} \sum_{i=1}^{m} I(f(x_i) \neq y_i)$
    - 精度：$Acc(f;D) = \frac{1}{m} \sum_{i=1}^{m} I(f(x_i) = y_i) = 1 - E(f;D)$
    - 混淆矩阵：
        - ![混淆矩阵](./assets/ML3.png)
        - 查重率-查准率曲线（P-R Curve）
        - F1值：$F_1 = \frac{2 \cdot P \cdot R}{P + R} = \frac{2 \cdot TP}{样例总数 + TP - TN}$

## 线性模型

对于由 $d$ 个属性描述的 Instance $x$，线性模型试图学得一个通过属性的线性组合来进行预测的函数，即 $f(x) = w_1 x_1 + w_2 x_2 + ... + w_d x_d + b = w \cdot x + b$。其中 $x_i$ 是 $x$ 在第 $i$ 个属性上的取值

